#!/usr/bin/env python3
"""
Script de dÃ©monstration des analyses avancÃ©es - Version locale
Peut Ãªtre exÃ©cutÃ© sans Spark pour dÃ©montrer les concepts
"""

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import json
from datetime import datetime


def create_sample_dataset():
    """
    CrÃ©e un dataset d'exemple de planÃ¨tes pour les analyses
    """
    data = [
        # PlanÃ¨tes habitables
        {
            "nom": "Kepler-442b",
            "masse": 2.34,
            "rayon": 1.34,
            "distance": 1206.0,
            "temperature": -40.0,
            "type": "super-terre",
            "eau": 1,
            "habitable": 1,
        },
        {
            "nom": "TRAPPIST-1e",
            "masse": 0.772,
            "rayon": 0.918,
            "distance": 39.0,
            "temperature": -22.0,
            "type": "terrestre",
            "eau": 1,
            "habitable": 1,
        },
        {
            "nom": "Proxima Centauri b",
            "masse": 1.17,
            "rayon": 1.1,
            "distance": 4.24,
            "temperature": -39.0,
            "type": "terrestre",
            "eau": 0,
            "habitable": 1,
        },
        {
            "nom": "Gliese 667Cc",
            "masse": 3.7,
            "rayon": 1.5,
            "distance": 23.6,
            "temperature": -3.0,
            "type": "super-terre",
            "eau": 1,
            "habitable": 1,
        },
        {
            "nom": "K2-18b",
            "masse": 8.6,
            "rayon": 2.3,
            "distance": 124.0,
            "temperature": -23.0,
            "type": "super-terre",
            "eau": 1,
            "habitable": 1,
        },
        # PlanÃ¨tes non habitables
        {
            "nom": "WASP-12b",
            "masse": 445.0,
            "rayon": 1.79,
            "distance": 871.0,
            "temperature": 2516.0,
            "type": "gÃ©ante gazeuse",
            "eau": 0,
            "habitable": 0,
        },
        {
            "nom": "CoRoT-7b",
            "masse": 4.8,
            "rayon": 1.58,
            "distance": 489.0,
            "temperature": 1800.0,
            "type": "super-terre",
            "eau": 0,
            "habitable": 0,
        },
        {
            "nom": "Kepler-7b",
            "masse": 150.0,
            "rayon": 1.48,
            "distance": 3000.0,
            "temperature": 1540.0,
            "type": "gÃ©ante gazeuse",
            "eau": 0,
            "habitable": 0,
        },
        {
            "nom": "OGLE-390Lb",
            "masse": 5.5,
            "rayon": 1.5,
            "distance": 21500.0,
            "temperature": -223.0,
            "type": "super-terre",
            "eau": 0,
            "habitable": 0,
        },
        {
            "nom": "PSR B1257+12",
            "masse": 0.02,
            "rayon": 0.5,
            "distance": 2300.0,
            "temperature": -213.0,
            "type": "terrestre",
            "eau": 0,
            "habitable": 0,
        },
    ]

    return pd.DataFrame(data)


def calculate_statistics(df):
    """
    Calcule les statistiques de base
    """
    print("ğŸ“Š STATISTIQUES DE BASE")
    print("=" * 50)

    print(f"Nombre total de planÃ¨tes: {len(df)}")
    print(f"PlanÃ¨tes habitables: {df['habitable'].sum()}")
    print(f"PlanÃ¨tes non habitables: {len(df) - df['habitable'].sum()}")

    print("\nğŸŒ Distribution par type:")
    print(df["type"].value_counts())

    print("\nğŸ“ˆ Statistiques numÃ©riques:")
    stats = df[["masse", "rayon", "distance", "temperature"]].describe()
    print(stats.round(2))

    return stats


def analyze_correlations(df):
    """
    Analyse les corrÃ©lations
    """
    print("\nğŸ”— ANALYSE DES CORRÃ‰LATIONS")
    print("=" * 50)

    numeric_cols = ["masse", "rayon", "distance", "temperature", "eau", "habitable"]
    correlation_matrix = df[numeric_cols].corr()

    print("Matrice de corrÃ©lation:")
    print(correlation_matrix.round(3))

    print("\nğŸ” CorrÃ©lations importantes avec l'habitabilitÃ©:")
    habitability_corr = correlation_matrix["habitable"].sort_values(
        key=abs, ascending=False
    )
    for feature, corr in habitability_corr.items():
        if feature != "habitable" and abs(corr) > 0.3:
            print(f"  {feature}: {corr:.3f}")

    return correlation_matrix


def perform_clustering(df):
    """
    Effectue un clustering des planÃ¨tes
    """
    print("\nğŸ¯ CLUSTERING DES PLANÃˆTES")
    print("=" * 50)

    # PrÃ©paration des donnÃ©es
    features = ["masse", "rayon", "distance", "temperature"]
    X = df[features].values

    # Normalisation
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # K-Means
    n_clusters = 3
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    clusters = kmeans.fit_predict(X_scaled)

    df["cluster"] = clusters

    print(f"Clustering en {n_clusters} groupes:")
    for i in range(n_clusters):
        cluster_planets = df[df["cluster"] == i]
        print(f"\nğŸŒŒ Cluster {i} ({len(cluster_planets)} planÃ¨tes):")
        print(f"  PlanÃ¨tes: {', '.join(cluster_planets['nom'].tolist())}")
        print(f"  Moyenne masse: {cluster_planets['masse'].mean():.2f}")
        print(f"  Moyenne tempÃ©rature: {cluster_planets['temperature'].mean():.2f}")
        print(f"  % habitables: {cluster_planets['habitable'].mean()*100:.1f}%")

    return df


def train_habitability_model(df):
    """
    EntraÃ®ne un modÃ¨le de prÃ©diction d'habitabilitÃ©
    """
    print("\nğŸ¤– MODÃˆLE D'IA: PRÃ‰DICTION D'HABITABILITÃ‰")
    print("=" * 50)

    # PrÃ©paration des features
    features = ["masse", "rayon", "distance", "temperature", "eau"]
    X = df[features].values
    y = df["habitable"].values

    # Division train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42
    )

    # EntraÃ®nement Random Forest
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)

    # PrÃ©dictions
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)

    print(f"ğŸ¯ PrÃ©cision du modÃ¨le: {accuracy:.2%}")

    # Importance des features
    feature_importance = list(zip(features, model.feature_importances_))
    feature_importance.sort(key=lambda x: x[1], reverse=True)

    print("\nğŸ“Š Importance des caractÃ©ristiques:")
    for feature, importance in feature_importance:
        print(f"  {feature}: {importance:.3f}")

    # Test sur de nouvelles planÃ¨tes
    print("\nğŸ”® PrÃ©dictions sur nouvelles planÃ¨tes:")
    new_planets = [
        ["PlanÃ¨te X1", 1.5, 1.2, 50.0, 10.0, 1],  # Potentiellement habitable
        ["PlanÃ¨te X2", 10.0, 3.0, 200.0, 500.0, 0],  # Non habitable
        ["PlanÃ¨te X3", 0.8, 0.9, 25.0, -10.0, 1],  # Potentiellement habitable
    ]

    for planet_data in new_planets:
        name = planet_data[0]
        features_values = planet_data[1:]
        prediction = model.predict([features_values])[0]
        probability = model.predict_proba([features_values])[0][1]

        habitability = "HABITABLE" if prediction == 1 else "NON HABITABLE"
        print(f"  {name}: {habitability} (probabilitÃ©: {probability:.2%})")

    return model


def detect_anomalies(df):
    """
    DÃ©tecte les anomalies dans les donnÃ©es
    """
    print("\nğŸš¨ DÃ‰TECTION D'ANOMALIES")
    print("=" * 50)

    anomalies = []
    numeric_cols = ["masse", "rayon", "distance", "temperature"]

    for col in numeric_cols:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1

        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        col_anomalies = df[(df[col] < lower_bound) | (df[col] > upper_bound)]

        if not col_anomalies.empty:
            print(f"\nğŸ“ Anomalies pour {col}:")
            print(f"  Seuils: [{lower_bound:.2f}, {upper_bound:.2f}]")
            for _, planet in col_anomalies.iterrows():
                print(f"    {planet['nom']}: {planet[col]:.2f}")
                anomalies.append(planet["nom"])

    unique_anomalies = list(set(anomalies))
    print(f"\nğŸ” PlanÃ¨tes avec anomalies: {len(unique_anomalies)}")
    for anomaly in unique_anomalies:
        print(f"  - {anomaly}")

    return unique_anomalies


def generate_report(df, stats, correlations, model, anomalies):
    """
    GÃ©nÃ¨re un rapport complet
    """
    print("\nğŸ“‹ RAPPORT FINAL")
    print("=" * 50)

    report = {
        "timestamp": datetime.now().isoformat(),
        "dataset": {
            "total_planets": len(df),
            "habitable_planets": int(df["habitable"].sum()),
            "planet_types": df["type"].value_counts().to_dict(),
        },
        "statistics": {
            "average_mass": float(df["masse"].mean()),
            "average_radius": float(df["rayon"].mean()),
            "average_temperature": float(df["temperature"].mean()),
            "habitable_percentage": float(df["habitable"].mean() * 100),
        },
        "correlations": {
            "water_temperature": float(correlations.loc["eau", "temperature"]),
            "mass_radius": float(correlations.loc["masse", "rayon"]),
            "habitability_temperature": float(
                correlations.loc["habitable", "temperature"]
            ),
        },
        "clustering": {
            "clusters_found": int(df["cluster"].nunique()),
            "cluster_distribution": df["cluster"].value_counts().to_dict(),
        },
        "anomalies": {"count": len(anomalies), "planets": anomalies},
        "model_performance": {
            "accuracy": "Ã‰valuÃ© sur Ã©chantillon test",
            "key_features": ["tempÃ©rature", "prÃ©sence d'eau", "masse"],
        },
    }

    # Sauvegarde du rapport
    with open("/tmp/planet_analysis_report.json", "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    print("âœ… Analyse complÃ¨te terminÃ©e!")
    print(f"ğŸ“„ Rapport sauvegardÃ©: /tmp/planet_analysis_report.json")
    print(f"ğŸŒ {report['dataset']['total_planets']} planÃ¨tes analysÃ©es")
    print(
        f"ğŸ¡ {report['dataset']['habitable_planets']} planÃ¨tes potentiellement habitables"
    )
    print(f"ğŸš¨ {report['anomalies']['count']} anomalies dÃ©tectÃ©es")


def main():
    """
    Fonction principale de dÃ©monstration
    """
    print("ğŸ”¬ ANALYSE AVANCÃ‰E DES DÃ‰COUVERTES DE PLANÃˆTES")
    print("Version de dÃ©monstration locale")
    print("=" * 60)

    # 1. CrÃ©ation du dataset
    df = create_sample_dataset()
    print(f"ğŸ“Š Dataset crÃ©Ã© avec {len(df)} planÃ¨tes")

    # 2. Statistiques de base
    stats = calculate_statistics(df)

    # 3. Analyse des corrÃ©lations
    correlations = analyze_correlations(df)

    # 4. Clustering
    df = perform_clustering(df)

    # 5. ModÃ¨le d'IA
    model = train_habitability_model(df)

    # 6. DÃ©tection d'anomalies
    anomalies = detect_anomalies(df)

    # 7. Rapport final
    generate_report(df, stats, correlations, model, anomalies)

    print("\nğŸŒ INTERFACES DISPONIBLES:")
    print("  - API Flask: http://localhost:5001")
    print("  - Kafka Topics: http://localhost:9092")

    print("\nğŸš€ PROCHAINES Ã‰TAPES:")
    print("  - DÃ©marrer les services Spark complets")
    print("  - Traitement streaming en temps rÃ©el")
    print("  - Stockage HDFS et Hive")


if __name__ == "__main__":
    main()
